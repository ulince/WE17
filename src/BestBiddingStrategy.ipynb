{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "validation_path = r\"..\\data\\validation.csv\"\n",
    "test_path = r\"C:..\\data\\test.csv\"\n",
    "output_path = r'..\\results\\test_bidprices.csv'\n",
    "DL_validation_data_path = r\"..\\data\\validation_data.p\"\n",
    "DL_validation_payprice_labels_path = r\"..\\data\\validation_labels_continuous.p\"\n",
    "DL_test_data_path = r\"..\\data\\test_data.p\"\n",
    "DL_test_labels_path = r\"..\\data\\test_labels_continuous.p\"\n",
    "validation_targets_path = r\"..\\data\\validation_targets.p\"\n",
    "model_dir_1 = r\"..\\model\"\n",
    "ctr_training_data_path = r\"..\\data\\ctr_training_data.p\"\n",
    "ctr_training_labels_path = r\"..\\data\\ctr_training_labels.p\"\n",
    "ctr_validation_data_path = r\"..\\data\\ctr_validation_data.p\"\n",
    "ctr_test_data_path = r\"..\\data\\ctr_test_data.p\"\n",
    "ctr_test_labels_path = r\"..\\data\\ctr_test_labels.p\"\n",
    "neg_weight = 0.0007539649884458758\n",
    "pos_weight = 0.9992460350115542\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "COLUMNS = ['weekday','hour','region','city','adexchange','advertiser','os','browser','usertag']\n",
    "LABEL_COLUMN = \"payprice\"\n",
    "CATEGORICAL_COLUMNS = ['weekday','hour','region','city','adexchange','advertiser','os','browser','usertag']\n",
    "WEIGHT_COLUMN = 'weight'\n",
    "USERTAGS = ['13776', '10133', '10146', '10052', '13800', '13678', '10077', '10057', '10048',\n",
    "            '16753', '16706', '10120', '11278', '10140', '10127', '10684', '10138', '10148', '11092',\n",
    "            '15398', '10067', '11632', '10117', '10114', '10145', '11576', '14273', '10059', '16617',\n",
    "            '10083', '13403', '10126', '11944', '13874', '11724', '10076', '10131', '10093', '11423',\n",
    "            '10110', '10123', '16751', '13496', '10149', '10111', '10031', '10142', '10118', '10074',\n",
    "            '10024', '16593', '10006', '10116', '11680', '10130', '10147', '10102', '10063',\n",
    "            '10075', '11512', '10129', '10079', '10125', '10115', '13042', '11379', '16661', '13866']\n",
    "\n",
    "dummy_data = ({'os': ['windows'], 'weekday': ['1'], 'browser': ['ie'], \n",
    "              'usertag': ['00000000000000000000000000000000000000000000000000000000010000000001'], \n",
    "              'weight': [0.0007539649884458758], 'city': ['85'], 'advertiser': ['1458'], 'region': ['80'],\n",
    "              'adexchange': ['2'], 'hour': ['14']},102)\n",
    "\n",
    "dnn_hidden_layers_param = [100,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic regression training\n",
    "def lr_train(data:list,labels:list):                \n",
    "    train_event_x = vectorizer.fit_transform(data)\n",
    "    train_event_y = label_encoder.fit_transform(labels)\n",
    "\n",
    "    p = 0.13\n",
    "    lr = LogisticRegression(C=p, class_weight={1: pos_weight, 0: neg_weight})\n",
    "    lr.fit(train_event_x, train_event_y)\n",
    "    \n",
    "    return lr\n",
    "\n",
    "def lr_evaluation(model,data):\n",
    "    event_x = vectorizer.transform(data)\n",
    "    event_y = label_encoder.inverse_transform(model.predict(event_x))\n",
    "    #event_y = model.predict_proba(event_x)\n",
    "    #print(event_y)\n",
    "    return event_y\n",
    "\n",
    "def load_data(path):\n",
    "    return pickle.load(open(path,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def restore_model(model_dir, dummy_data, model_type=None):\n",
    "    weekday = tf.contrib.layers.sparse_column_with_keys(column_name=\"weekday\",\n",
    "                                                     keys=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\n",
    "                                                     combiner=\"sqrtn\")\n",
    "    hour = tf.contrib.layers.sparse_column_with_keys(column_name=\"hour\",\n",
    "                                                     keys=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"\n",
    "                                                          \"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\n",
    "                                                           \"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\n",
    "                                                           \"22\",\"23\"],\n",
    "                                                    combiner=\"sqrtn\")\n",
    "    region = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"region\", hash_bucket_size=100,combiner=\"sqrtn\")\n",
    "    city = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"city\", hash_bucket_size=1000,combiner=\"sqrtn\")\n",
    "    adexchange = tf.contrib.layers.sparse_column_with_keys(column_name=\"adexchange\",\n",
    "                                                     keys=[\"1\",\"2\",\"3\",\"4\",\"null\"],\n",
    "                                                          combiner=\"sqrtn\")\n",
    "    advertiser = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"advertiser\", hash_bucket_size=20,combiner=\"sqrtn\")\n",
    "    os = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"os\", hash_bucket_size=100,combiner=\"sqrtn\")\n",
    "    browser = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"browser\", hash_bucket_size=100,combiner=\"sqrtn\")\n",
    "    usertag = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"usertag\", hash_bucket_size=1000000,combiner=\"sqrtn\")\n",
    "    \n",
    "    # Wide columns and deep columns.\n",
    "    wide_columns = [weekday,hour,region,city,adexchange,advertiser,os,browser,usertag]\n",
    "\n",
    "    deep_columns = [\n",
    "      tf.contrib.layers.embedding_column(weekday, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(hour, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(region, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(city,dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(adexchange, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(advertiser, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(os, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(browser, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(usertag, dimension=8,combiner=\"sqrtn\"),\n",
    "      ]\n",
    "    \n",
    "    if model_type == 'CTR_estimator':\n",
    "        weight_column = tf.contrib.layers.real_valued_column(\"weight\")\n",
    "        \n",
    "        model = tf.contrib.learn.DNNLinearCombinedClassifier(\n",
    "            # wide settings\n",
    "            linear_feature_columns=wide_columns,\n",
    "            linear_optimizer=tf.train.FtrlOptimizer(learning_rate=0.1,\n",
    "                                                l1_regularization_strength=0.001,\n",
    "                                                l2_regularization_strength=0.001),\n",
    "            # deep settings\n",
    "            dnn_feature_columns=deep_columns,\n",
    "            #dnn_hidden_units=[1000, 500, 100],\n",
    "            dnn_hidden_units=[100,50],\n",
    "            dnn_optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=0.1,\n",
    "                                                        l1_regularization_strength=0.001,\n",
    "                                                        l2_regularization_strength=0.001),\n",
    "            config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1800),\n",
    "            n_classes=31,\n",
    "            model_dir=model_dir,\n",
    "            weight_column_name = WEIGHT_COLUMN\n",
    "        )\n",
    "        \n",
    "        model.fit(input_fn=lambda: input_fn(dummy_data[0],dummy_data[2],model_type), steps=1)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        model = tf.contrib.learn.DNNLinearCombinedRegressor(\n",
    "            # wide settings\n",
    "            linear_feature_columns=wide_columns,\n",
    "            linear_optimizer=tf.train.FtrlOptimizer(learning_rate=0.1,\n",
    "                                                    l1_regularization_strength=0.001,\n",
    "                                                    l2_regularization_strength=0.001),\n",
    "            #deep settings\n",
    "            dnn_feature_columns=deep_columns,\n",
    "            #dnn_hidden_units=[1000, 500, 100],\n",
    "            dnn_hidden_units=dnn_hidden_layers_param,\n",
    "            dnn_optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=0.1,\n",
    "                                                            l1_regularization_strength=0.001,\n",
    "                                                            l2_regularization_strength=0.001),\n",
    "            config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1800),\n",
    "            model_dir=model_dir\n",
    "        )\n",
    "        \n",
    "        model.fit(input_fn=lambda: input_fn(dummy_data[0],[dummy_data[1]]), steps=1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def input_fn(data,labels, first=None, last=None):\n",
    "    categorical_cols = {}\n",
    "    for k in CATEGORICAL_COLUMNS:\n",
    "        categorical_cols[k] = tf.SparseTensor(\n",
    "            indices=[[i, 0] for i in range(len(data[k][first:last]))],\n",
    "            values=data[k][first:last],\n",
    "            shape=[len(data[k][first:last]),1])\n",
    "    \n",
    "    label = tf.constant(labels[first:last])\n",
    "    return categorical_cols, label\n",
    "\n",
    "def predict(model,data,labels):\n",
    "    return model.predict(input_fn=lambda: input_fn(data,labels), as_iterable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RTB_simulation(CTR_predictions,bid_predictions,targets,start_budget = 6250000):\n",
    "    impressions = 0\n",
    "    clicks = 0\n",
    "    budget=start_budget\n",
    "    total_bids = 0\n",
    "    bids_won = 0\n",
    "    spent = 0\n",
    "\n",
    "    for i in range(0,CTR_predictions.shape[0]):\n",
    "        if CTR_predictions[i][0] > CTR_predictions[i][1]: #Do not bid\n",
    "            continue\n",
    "        else:\n",
    "            current_bid = bid_predictions[i]\n",
    "            # Check if we still have budget:\n",
    "            if budget > current_bid:\n",
    "                # Get the market price:\n",
    "                payprice = targets[i][1]\n",
    "                # Check if we win the bid:\n",
    "                total_bids += 1\n",
    "                if current_bid > payprice:\n",
    "                    bids_won += 1\n",
    "                    impressions += 1\n",
    "                    budget -= payprice\n",
    "                    spent += payprice\n",
    "                    # Check if the person clicks:\n",
    "                    if targets[i][0] == \"1\":\n",
    "                        clicks += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    ctr = 0\n",
    "    avgCPM = 0\n",
    "    avgCPC = 0\n",
    "\n",
    "    if clicks > 0:\n",
    "        avgCPC = spent/clicks\n",
    "    if impressions > 0:\n",
    "        avgCPM = spent/impressions\n",
    "        ctr = (clicks/impressions)*100\n",
    "\n",
    "    print(\"Total bids made: \" + str(total_bids))\n",
    "    print(\"Impressions:{0}\".format(impressions))\n",
    "    print(\"Percent of bids won: \" + str(impressions*100/total_bids))\n",
    "    print(\"Clicks:{0}\".format(clicks))\n",
    "    print(\"avgCPM:\" + str(avgCPM))\n",
    "    print(\"avgCPC:\" + str(avgCPC))\n",
    "    print(\"Spent:\" + str(spent))\n",
    "    return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "validation_data = load_data(DL_validation_data_path)\n",
    "validation_payprice_labels = load_data(DL_validation_payprice_labels_path)\n",
    "targets = load_data(validation_targets_path)\n",
    "ctr_training_data = load_data(ctr_training_data_path)\n",
    "ctr_training_labels = load_data(ctr_training_labels_path)\n",
    "ctr_validation_data = load_data(ctr_validation_data_path)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Training CTR_estimator\")\n",
    "ctr_estimator = lr_train(ctr_training_data,ctr_training_labels)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Restoring payprice_estimator\")\n",
    "payprice_estimator = restore_model(model_dir_1,dummy_data,model_type=\"payprice_estimator\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating CTR_estimator\")\n",
    "ctr_results = lr_evaluation(ctr_estimator,ctr_validation_data)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating payprice_estimator\")\n",
    "payprice_results = predict(payprice_estimator,validation_data,validation_payprice_labels)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting simulation\")\n",
    "CTR = RTB_simulation(ctr_results,payprice_results,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_dump_test(CTR_predictions,bid_predictions,targets,start_budget = 6250000):\n",
    "    impressions = 0\n",
    "    clicks = 0\n",
    "    budget=start_budget\n",
    "    total_bids = 0\n",
    "    bids_won = 0\n",
    "    i = -1\n",
    "    results = [(\"bidid\",\"bidprice\",\"advertiser\", \"pCTR\")]\n",
    "    advertisers = {}\n",
    "    \n",
    "    with open(test_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')  \n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            i += 1\n",
    "            adver = row[21]\n",
    "            if adver not in advertisers.keys():\n",
    "                advertisers[adver] = {'impressions':0,'clicks':0,'ctr':0,'estimated 0s':0,\n",
    "                                      'estimated 1s':0}\n",
    "            \n",
    "            if CTR_predictions[i][0] > CTR_predictions[i][1]: #Do not bid\n",
    "                advertisers[adver]['estimated 0s'] = advertisers[adver]['estimated 0s'] + 1\n",
    "                results.append((row[2],0,adver,CTR_predictions[i][1]))\n",
    "                continue\n",
    "            else:\n",
    "                current_bid = bid_predictions[i]\n",
    "                results.append((row[2],current_bid,adver,CTR_predictions[i][1]))\n",
    "\n",
    "    return results,advertisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting...\")\n",
    "to_csv,per_advertiser = data_dump_test(ctr_results,payprice_results,targets)\n",
    "df = pd.DataFrame(to_csv)\n",
    "df.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
