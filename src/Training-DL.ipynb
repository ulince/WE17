{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "data_path = r\"..\\data\\training_data.p\"\n",
    "labels_path = r\"..\\data\\training_labels_continuous.p\"\n",
    "validation_data_path = r\"..\\data\\validation_data.p\"\n",
    "validation_labels_path = r\"..\\data\\validation_labels_continuous.p\"\n",
    "validation_targets_path = r\"..\\data\\validation_targets.p\"\n",
    "model_dir = r\"..\\model\"\n",
    "\n",
    "COLUMNS = ['weekday','hour','region','city','adexchange','advertiser','os','browser','usertag']\n",
    "LABEL_COLUMN = \"payprice\"\n",
    "CATEGORICAL_COLUMNS = ['weekday','hour','region','city','adexchange','advertiser','os','browser','usertag']\n",
    "\n",
    "USERTAGS = ['13776', '10133', '10146', '10052', '13800', '13678', '10077', '10057', '10048',\n",
    "            '16753', '16706', '10120', '11278', '10140', '10127', '10684', '10138', '10148', '11092',\n",
    "            '15398', '10067', '11632', '10117', '10114', '10145', '11576', '14273', '10059', '16617',\n",
    "            '10083', '13403', '10126', '11944', '13874', '11724', '10076', '10131', '10093', '11423',\n",
    "            '10110', '10123', '16751', '13496', '10149', '10111', '10031', '10142', '10118', '10074',\n",
    "            '10024', '16593', '10006', '10116', '11680', '10130', '10147', '10102', '10063',\n",
    "            '10075', '11512', '10129', '10079', '10125', '10115', '13042', '11379', '16661', '13866']\n",
    "\n",
    "dnn_hidden_layers_param = [100,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    return pickle.load(open(path,\"rb\"))\n",
    "\n",
    "def build_estimator(model_dir,model_type=None):\n",
    "    weekday = tf.contrib.layers.sparse_column_with_keys(column_name=\"weekday\",\n",
    "                                                     keys=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\n",
    "                                                     combiner=\"sqrtn\")\n",
    "    hour = tf.contrib.layers.sparse_column_with_keys(column_name=\"hour\",\n",
    "                                                     keys=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"\n",
    "                                                          \"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\n",
    "                                                           \"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\n",
    "                                                           \"22\",\"23\"],\n",
    "                                                    combiner=\"sqrtn\")\n",
    "    region = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"region\", hash_bucket_size=100,combiner=\"sqrtn\")\n",
    "    city = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"city\", hash_bucket_size=1000,combiner=\"sqrtn\")\n",
    "    adexchange = tf.contrib.layers.sparse_column_with_keys(column_name=\"adexchange\",\n",
    "                                                     keys=[\"1\",\"2\",\"3\",\"4\",\"null\"],\n",
    "                                                          combiner=\"sqrtn\")\n",
    "    advertiser = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"advertiser\", hash_bucket_size=20,combiner=\"sqrtn\")\n",
    "    os = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"os\", hash_bucket_size=100,combiner=\"sqrtn\")\n",
    "    browser = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"browser\", hash_bucket_size=100,combiner=\"sqrtn\")\n",
    "    usertag = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"usertag\", hash_bucket_size=1000000,combiner=\"sqrtn\")\n",
    "\n",
    "    # Wide columns and deep columns.\n",
    "    wide_columns = [weekday,hour,region,city,adexchange,advertiser,os,browser,usertag]\n",
    "\n",
    "    deep_columns = [\n",
    "      tf.contrib.layers.embedding_column(weekday, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(hour, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(region, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(city,dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(adexchange, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(advertiser, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(os, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(browser, dimension=4,combiner=\"sqrtn\"),\n",
    "      tf.contrib.layers.embedding_column(usertag, dimension=8,combiner=\"sqrtn\"),\n",
    "      ]\n",
    "    \n",
    "    estimator = tf.contrib.learn.DNNLinearCombinedRegressor(\n",
    "        # wide settings\n",
    "        linear_feature_columns=wide_columns,\n",
    "        linear_optimizer=tf.train.FtrlOptimizer(learning_rate=0.1,\n",
    "                                                l1_regularization_strength=0.001,\n",
    "                                                l2_regularization_strength=0.001),\n",
    "        # deep settings\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_hidden_units=dnn_hidden_layers_param,\n",
    "        dnn_optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=0.1,\n",
    "                                                        l1_regularization_strength=0.001,\n",
    "                                                        l2_regularization_strength=0.001),\n",
    "        config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1800),\n",
    "        model_dir=model_dir\n",
    "    )\n",
    "    \n",
    "    return estimator\n",
    "\n",
    "def input_fn(data,labels, first=None, last=None):\n",
    "    categorical_cols = {}\n",
    "    for k in CATEGORICAL_COLUMNS:\n",
    "        categorical_cols[k] = tf.SparseTensor(\n",
    "            indices=[[i, 0] for i in range(len(data[k][first:last]))],\n",
    "            values=data[k][first:last],\n",
    "            shape=[len(data[k][first:last]),1])\n",
    "    \n",
    "    label = tf.constant(labels[first:last])\n",
    "    return categorical_cols, label\n",
    "\n",
    "\n",
    "def train(data,labels,model_dir, epochs=200):\n",
    "    size_limit = len(data['weekday']) - 10000\n",
    "    m = build_estimator(model_dir)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if i % 10 == 0:\n",
    "            print(\"Training step: \" + str(i))\n",
    "        starting_index = randint(0,size_limit)\n",
    "        last_index = starting_index + 10000\n",
    "        m.partial_fit(input_fn=lambda: input_fn(data,labels,starting_index,last_index), steps=1)\n",
    "    \n",
    "    return m\n",
    "\n",
    "def predict(model,data,labels):\n",
    "    return model.predict(input_fn=lambda: input_fn(data,labels), as_iterable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "training_data = load_data(data_path)\n",
    "training_labels = load_data(labels_path)\n",
    "validation_data = load_data(validation_data_path)\n",
    "validation_labels = load_data(validation_labels_path)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Training model\")\n",
    "model = train(training_data, training_labels,model_dir,epochs=200);\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating model\")\n",
    "results = predict(model,validation_data,validation_labels)\n",
    "y_est = np.array(results).astype(int).clip(0,200)\n",
    "y_true = np.array(validation_labels)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_true,y_est))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
